import { env } from "../../../config/environment";
import { OpenAIEmbeddings } from "langchain/embeddings/openai";
import OpenAI from "openai";
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { MemoryVectorStore } from 'langchain/vectorstores/memory';
import { BraveSearch } from "@langchain/community/tools/brave_search";
import cheerio from 'cheerio';
import { ConfigOptions } from "../../../common/interfaces/ConfigOptions.interface";

// ƒë·∫ßu ti√™n khai b√°o openai
let openai = new OpenAI({
  baseURL: 'https://api.groq.com/openai/v1',
  apiKey: env.GROQ_API_KEY,
});
// khai b√°o embedding
const embeddings = new OpenAIEmbeddings();

// h√†m l·∫•y c√°c c√¢u h·ªèi li√™n quan ti·∫øp theo 
async function generateFollowUpQuestions(responseText: string) {
  const a = performance.now();
  const groqResponse = await openai.chat.completions.create({
    model: "mixtral-8x7b-32768",
    messages: [
      { role: "system", content: "You are a question generator. Generate 3 follow-up questions based on the provided text. Return the questions in an array format." },
      {
        role: "user",
        content: `Generate 3 follow-up questions based on the following text:\n\n${responseText}\n\nReturn the questions in the following format: ["Question 1", "Question 2", "Question 3"]`
      }
    ],
  });
  const b = performance.now();
  console.log('===============generateFollowUpQuestions took ' + (b - a) + ' ms.===================');
  return JSON.parse(groqResponse.choices[0].message.content ?? "");
}

export const getAnswerResearchAssistant1 = async (datas: ConfigOptions) => {
  // Ph√¢n t√≠ch datas
  const { message, returnSources = true, returnFollowUpQuestions = true, embedSourcesInLLMResponse = false, textChunkSize = 800, textChunkOverlap = 200, numberOfSimilarityResults = 2, numberOfPagesToScan = 4 } = datas;

  // t√°i c√¢u tr√∫c l·∫°i c√¢u h·ªèi ƒë∆∞·ª£c ƒë∆∞a ra => c√¢u h·ªèi s·∫Ω v√†o tr·ªçng t√¢m
  async function rephraseInput(inputString: string): Promise<string> {
    console.log(`4. Rephrasing input`);
    const groqResponse = await openai.chat.completions.create({
      model: "mixtral-8x7b-32768",
      messages: [
        { role: "system", content: "You are a rephraser and always respond with a rephrased VIETNAMESE version of the input that is given to a search engine API. Always be succint and use the same words as the input. RETURN ONLY A REVISED VIETNAMESE VERSION OF THE INPUT AND ADD NO MORE SENTENCES." },
        { role: "user", content: inputString },
      ],
    });
    console.log(`5. Rephrased input and got answer from Groq`);
    return groqResponse.choices[0].message.content ?? "";
  }
  // 10. 
  async function searchEngineForSources(message: string) {
    console.log(`3. Initializing Search Engine Process`);
    // 11. Kh·ªüi t·∫°o BraveSearch
    const loader = new BraveSearch({ apiKey: env.BRAVE_SEARCH_API_KEY });
    // 12. T√°i c·∫•u tr√∫c l·∫°i c√¢u h·ªèi
    const rephrasedMessage = await rephraseInput(message);
    console.log(`6. Rephrased message and got documents from BraveSearch: `, rephrasedMessage);
    // 13. L·∫•y documents t·ª´ BraveSearch 
    const docs = await loader.call(rephrasedMessage);
    // 14. Normalize data => n√†y s·∫Ω chuy·ªÉn d·∫°ng data: { title: string, link: string}
    const normalizedData = normalizeData(docs);
    console.log("üöÄ ~ searchEngineForSources ~ normalizedData:", normalizedData)
    // 15. Process and vectorize the content
    return await Promise.all(normalizedData.map(fetchAndProcess));
  }
  // 16. Normalize data
  function normalizeData(docs: any) {
    return JSON.parse(docs)
      // l·ªçc doc c√≥ title v√† link v√† kh√¥ng ch·ª©a t√™n mi·ªÅn brave.com
      .filter((doc: any) => doc.title && doc.link && !doc.link.includes("brave.com"))
      // t√°ch l·∫•y numberOfPagesToScan ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n 
      .slice(0, numberOfPagesToScan)
      // chuy·ªÉn m·∫£ng ban ƒë·∫ßu v·ªÅ d·∫°ng c√≥ m·∫£ng 2 property: title: string, link: string  
      .map(({ title, link }: { title: string, link: string }) => ({ title, link }));
  }
  // 17. L·∫•y n·ªôi dung c·ªßa 1 trang v·ªÅ
  const fetchPageContent = async (link: string) => {
    console.log(`7. Fetching page content for ${link}`);
    try {
      const response = await fetch(link);
      if (!response.ok) {
        return ""; // skip if fetch fails
      }
      // html d·∫°ng text
      const text = await response.text();
      return extractMainContent(text, link);
    } catch (error) {
      console.error(`Error fetching page content for ${link}:`, error);
      return '';
    }
  };
  // 18. Tr√≠ch xu·∫•t n·ªôi dung t·ª´ 1 text html 
  function extractMainContent(html: string, link: string) {
    console.log(`8. Extracting main content from HTML for ${link}`);

    const $ = html.length ? cheerio.load(html) : null
    if ($) {
      // x√≥a c√°c th·∫ª kh√¥ng c·∫ßn thi·∫øt
      $("script, style, head, nav, footer, iframe, img").remove();
      // tr√≠ch xu·∫•t text t·ª´ body sau ƒë√≥ thay th·∫ø c√°c kho·∫£ng( bao g·ªìm d·∫•u c√°ch, tab, d√≤ng m·ªõi,...) th√†nh " " v√†o x√≥a kho·∫£ng tr·∫Øng hai ƒë·∫ßu
      return $("body").text().replace(/\s+/g, " ").trim();
    } else return ""
  }
  // 19. X·ª≠ l√Ω v√† chuy·ªÉn text ƒë√£ l·∫•y ƒë∆∞·ª£c t·ª´ trang web v·ªÅ d·∫°ng vector
  let vectorCount = 0;
  const fetchAndProcess = async (item: any) => {
    const a = performance.now();
    // l·∫•y t·∫•t c·∫£ n·ªôi dung ch√≠nh trong trang web 
    const htmlContent = await fetchPageContent(item.link);
    // kh√¥ng l·∫•y n·ªôi d·ª•ng < 250 k√Ω (v√¨ ƒë√¢y c√≥ th·ªÉ l√† qu·∫£ng c√°o)
    if (htmlContent && htmlContent.length < 250) return null;
    // t√°ch k√Ω t·ª± v·ªõi textChunkSize k√Ω t·ª± v√† ch·ªìng ch√©o textChunkOverlap k√Ω t·ª±
    const splitText = await new RecursiveCharacterTextSplitter({ chunkSize: textChunkSize, chunkOverlap: textChunkOverlap }).splitText(htmlContent);
    // l∆∞u d·∫°ng vector
    const vectorStore = await MemoryVectorStore.fromTexts(splitText, { link: item.link, title: item.title }, embeddings);
    vectorCount++;
    console.log(`9. Processed ${vectorCount} sources for ${item.link}`);
    // t√¨m c√°c doc t∆∞∆°ng ·ª©ng v·ªõi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng 
    const similaritySearch = await vectorStore.similaritySearch(message, numberOfSimilarityResults);
    const b = performance.now();
    console.log('===============fetchAndProcess took ' + (b - a) + ' ms.===================');
    return similaritySearch
  };
  // 20. n·∫°p v√† x·ª≠ l√Ω c√°c t√†i nguy√™n
  const sources = await searchEngineForSources(message);
  return sources;
  // const sourcesParsed = sources.map(group =>
  //   group.map((doc: any) => {
  //     const title = doc.metadata.title;
  //     const link = doc.metadata.link;
  //     return { title, link };
  //   })
  //     .filter((doc: any, index: number, self: any) => self.findIndex((d: any) => d.link === doc.link) === index)
  // );
  // console.log(`10. RAG complete sources and preparing response content`);
  // // 21. Chu·∫©n b·ªã cho ph·∫£n h·ªìi
  // const chatCompletion = await openai.chat.completions.create({
  //   messages:
  //     [{
  //       role: "system", content: `
  //       - Here is my query "${message}", respond back with an answer that is as long as possible. If you can't find any relevant results, respond with "No relevant results found." 
  //       - ${embedSourcesInLLMResponse ? "Return the sources used in the response with iterable numbered markdown style annotations." : ""}" : ""}`
  //     },
  //     { role: "user", content: ` - Here are the top results from a similarity search: ${JSON.stringify(sources)}. ` },
  //     ], stream: true, model: "mixtral-8x7b-32768"
  // });
  // console.log(`11. Sent content to Groq for chat completion.`);
  // let responseTotal = "";
  // console.log(`12. Streaming response from Groq... \n`);
  // for await (const chunk of chatCompletion) {
  //   if (chunk.choices[0].delta && chunk.choices[0].finish_reason !== "stop") {
  //     // process.stdout.write(chunk.choices[0].delta.content);
  //     responseTotal += chunk.choices[0].delta.content;
  //   } else {
  //     let responseObj: {
  //       sources?: any,
  //       answer?: any,
  //       followUpQuestions?: any
  //     } = {};
  //     returnSources ? responseObj.sources = sourcesParsed : null;
  //     responseObj.answer = responseTotal;
  //     returnFollowUpQuestions ? responseObj.followUpQuestions = await generateFollowUpQuestions(responseTotal) : null;
  //     console.log(`\n\n13. Generated follow-up questions:  ${JSON.stringify(responseObj.followUpQuestions)}`);
  //     return responseObj;
  //   }
  // }
}