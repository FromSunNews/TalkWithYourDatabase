"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getAnswerResearchAssistant1 = void 0;
const environment_1 = require("../../../config/environment");
const openai_1 = require("langchain/embeddings/openai");
const openai_2 = __importDefault(require("openai"));
const text_splitter_1 = require("langchain/text_splitter");
const memory_1 = require("langchain/vectorstores/memory");
const brave_search_1 = require("@langchain/community/tools/brave_search");
const cheerio_1 = __importDefault(require("cheerio"));
// ƒë·∫ßu ti√™n khai b√°o openai
let openai = new openai_2.default({
    baseURL: 'https://api.groq.com/openai/v1',
    apiKey: environment_1.env.GROQ_API_KEY,
});
// khai b√°o embedding
const embeddings = new openai_1.OpenAIEmbeddings();
// h√†m l·∫•y c√°c c√¢u h·ªèi li√™n quan ti·∫øp theo 
async function generateFollowUpQuestions(responseText) {
    const a = performance.now();
    const groqResponse = await openai.chat.completions.create({
        model: "mixtral-8x7b-32768",
        messages: [
            { role: "system", content: "You are a question generator. Generate 3 follow-up questions based on the provided text. Return the questions in an array format." },
            {
                role: "user",
                content: `Generate 3 follow-up questions based on the following text:\n\n${responseText}\n\nReturn the questions in the following format: ["Question 1", "Question 2", "Question 3"]`
            }
        ],
    });
    const b = performance.now();
    console.log('===============generateFollowUpQuestions took ' + (b - a) + ' ms.===================');
    return JSON.parse(groqResponse.choices[0].message.content ?? "");
}
const getAnswerResearchAssistant1 = async (datas) => {
    // Ph√¢n t√≠ch datas
    const { message, returnSources = true, returnFollowUpQuestions = true, embedSourcesInLLMResponse = false, textChunkSize = 800, textChunkOverlap = 200, numberOfSimilarityResults = 2, numberOfPagesToScan = 4 } = datas;
    // t√°i c√¢u tr√∫c l·∫°i c√¢u h·ªèi ƒë∆∞·ª£c ƒë∆∞a ra => c√¢u h·ªèi s·∫Ω v√†o tr·ªçng t√¢m
    async function rephraseInput(inputString) {
        console.log(`4. Rephrasing input`);
        const groqResponse = await openai.chat.completions.create({
            model: "mixtral-8x7b-32768",
            messages: [
                { role: "system", content: "You are a rephraser and always respond with a rephrased VIETNAMESE version of the input that is given to a search engine API. Always be succint and use the same words as the input. RETURN ONLY A REVISED VIETNAMESE VERSION OF THE INPUT AND ADD NO MORE SENTENCES." },
                { role: "user", content: inputString },
            ],
        });
        console.log(`5. Rephrased input and got answer from Groq`);
        return groqResponse.choices[0].message.content ?? "";
    }
    // 10. 
    async function searchEngineForSources(message) {
        console.log(`3. Initializing Search Engine Process`);
        // 11. Kh·ªüi t·∫°o BraveSearch
        const loader = new brave_search_1.BraveSearch({ apiKey: environment_1.env.BRAVE_SEARCH_API_KEY });
        // 12. T√°i c·∫•u tr√∫c l·∫°i c√¢u h·ªèi
        const rephrasedMessage = await rephraseInput(message);
        console.log(`6. Rephrased message and got documents from BraveSearch: `, rephrasedMessage);
        // 13. L·∫•y documents t·ª´ BraveSearch 
        const docs = await loader.call(rephrasedMessage);
        // 14. Normalize data => n√†y s·∫Ω chuy·ªÉn d·∫°ng data: { title: string, link: string}
        const normalizedData = normalizeData(docs);
        console.log("üöÄ ~ searchEngineForSources ~ normalizedData:", normalizedData);
        // 15. Process and vectorize the content
        return await Promise.all(normalizedData.map(fetchAndProcess));
    }
    // 16. Normalize data
    function normalizeData(docs) {
        return JSON.parse(docs)
            // l·ªçc doc c√≥ title v√† link v√† kh√¥ng ch·ª©a t√™n mi·ªÅn brave.com
            .filter((doc) => doc.title && doc.link && !doc.link.includes("brave.com"))
            // t√°ch l·∫•y numberOfPagesToScan ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n 
            .slice(0, numberOfPagesToScan)
            // chuy·ªÉn m·∫£ng ban ƒë·∫ßu v·ªÅ d·∫°ng c√≥ m·∫£ng 2 property: title: string, link: string  
            .map(({ title, link }) => ({ title, link }));
    }
    // 17. L·∫•y n·ªôi dung c·ªßa 1 trang v·ªÅ
    const fetchPageContent = async (link) => {
        console.log(`7. Fetching page content for ${link}`);
        try {
            const response = await fetch(link);
            if (!response.ok) {
                return ""; // skip if fetch fails
            }
            // html d·∫°ng text
            const text = await response.text();
            return extractMainContent(text, link);
        }
        catch (error) {
            console.error(`Error fetching page content for ${link}:`, error);
            return '';
        }
    };
    // 18. Tr√≠ch xu·∫•t n·ªôi dung t·ª´ 1 text html 
    function extractMainContent(html, link) {
        console.log(`8. Extracting main content from HTML for ${link}`);
        const $ = html.length ? cheerio_1.default.load(html) : null;
        if ($) {
            // x√≥a c√°c th·∫ª kh√¥ng c·∫ßn thi·∫øt
            $("script, style, head, nav, footer, iframe, img").remove();
            // tr√≠ch xu·∫•t text t·ª´ body sau ƒë√≥ thay th·∫ø c√°c kho·∫£ng( bao g·ªìm d·∫•u c√°ch, tab, d√≤ng m·ªõi,...) th√†nh " " v√†o x√≥a kho·∫£ng tr·∫Øng hai ƒë·∫ßu
            return $("body").text().replace(/\s+/g, " ").trim();
        }
        else
            return "";
    }
    // 19. X·ª≠ l√Ω v√† chuy·ªÉn text ƒë√£ l·∫•y ƒë∆∞·ª£c t·ª´ trang web v·ªÅ d·∫°ng vector
    let vectorCount = 0;
    const fetchAndProcess = async (item) => {
        const a = performance.now();
        // l·∫•y t·∫•t c·∫£ n·ªôi dung ch√≠nh trong trang web 
        const htmlContent = await fetchPageContent(item.link);
        // kh√¥ng l·∫•y n·ªôi d·ª•ng < 250 k√Ω (v√¨ ƒë√¢y c√≥ th·ªÉ l√† qu·∫£ng c√°o)
        if (htmlContent && htmlContent.length < 250)
            return null;
        // t√°ch k√Ω t·ª± v·ªõi textChunkSize k√Ω t·ª± v√† ch·ªìng ch√©o textChunkOverlap k√Ω t·ª±
        const splitText = await new text_splitter_1.RecursiveCharacterTextSplitter({ chunkSize: textChunkSize, chunkOverlap: textChunkOverlap }).splitText(htmlContent);
        // l∆∞u d·∫°ng vector
        const vectorStore = await memory_1.MemoryVectorStore.fromTexts(splitText, { link: item.link, title: item.title }, embeddings);
        vectorCount++;
        console.log(`9. Processed ${vectorCount} sources for ${item.link}`);
        // t√¨m c√°c doc t∆∞∆°ng ·ª©ng v·ªõi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng 
        const similaritySearch = await vectorStore.similaritySearch(message, numberOfSimilarityResults);
        const b = performance.now();
        console.log('===============fetchAndProcess took ' + (b - a) + ' ms.===================');
        return similaritySearch;
    };
    // 20. n·∫°p v√† x·ª≠ l√Ω c√°c t√†i nguy√™n
    const sources = await searchEngineForSources(message);
    return sources;
    // const sourcesParsed = sources.map(group =>
    //   group.map((doc: any) => {
    //     const title = doc.metadata.title;
    //     const link = doc.metadata.link;
    //     return { title, link };
    //   })
    //     .filter((doc: any, index: number, self: any) => self.findIndex((d: any) => d.link === doc.link) === index)
    // );
    // console.log(`10. RAG complete sources and preparing response content`);
    // // 21. Chu·∫©n b·ªã cho ph·∫£n h·ªìi
    // const chatCompletion = await openai.chat.completions.create({
    //   messages:
    //     [{
    //       role: "system", content: `
    //       - Here is my query "${message}", respond back with an answer that is as long as possible. If you can't find any relevant results, respond with "No relevant results found." 
    //       - ${embedSourcesInLLMResponse ? "Return the sources used in the response with iterable numbered markdown style annotations." : ""}" : ""}`
    //     },
    //     { role: "user", content: ` - Here are the top results from a similarity search: ${JSON.stringify(sources)}. ` },
    //     ], stream: true, model: "mixtral-8x7b-32768"
    // });
    // console.log(`11. Sent content to Groq for chat completion.`);
    // let responseTotal = "";
    // console.log(`12. Streaming response from Groq... \n`);
    // for await (const chunk of chatCompletion) {
    //   if (chunk.choices[0].delta && chunk.choices[0].finish_reason !== "stop") {
    //     // process.stdout.write(chunk.choices[0].delta.content);
    //     responseTotal += chunk.choices[0].delta.content;
    //   } else {
    //     let responseObj: {
    //       sources?: any,
    //       answer?: any,
    //       followUpQuestions?: any
    //     } = {};
    //     returnSources ? responseObj.sources = sourcesParsed : null;
    //     responseObj.answer = responseTotal;
    //     returnFollowUpQuestions ? responseObj.followUpQuestions = await generateFollowUpQuestions(responseTotal) : null;
    //     console.log(`\n\n13. Generated follow-up questions:  ${JSON.stringify(responseObj.followUpQuestions)}`);
    //     return responseObj;
    //   }
    // }
};
exports.getAnswerResearchAssistant1 = getAnswerResearchAssistant1;
//# sourceMappingURL=index%20copy.js.map